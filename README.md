# üß¨ PathoNet-X: Attention-Driven CNN for Histopathological Image Diagnosis

## üìò Overview
**PatchCamelyon (PCam)** is a histopathology image classification project leveraging **Convolutional Neural Networks (CNNs)** and an **Attention Mechanism** to detect metastatic cancer in lymph node tissue.  
The project uses the **PatchCamelyon dataset (PCam)** ‚Äî a benchmark dataset derived from the **Camelyon16** challenge ‚Äî and aims to enhance classification accuracy and interpretability through **visual attention maps** and **Grad-CAM** visualization.

---

## üéØ Objective
To design and train a **deep learning model** capable of accurately classifying histopathology image patches into cancerous or non-cancerous categories using:
- **CNNs** for spatial feature extraction  
- **Attention mechanisms** for focusing on the most relevant regions  
- **Grad-CAM** for visual interpretability  

---

## üöÄ Goals
- Achieve high accuracy and F1 score on the PatchCamelyon dataset.  
- Improve interpretability of medical imaging AI through attention and heatmap visualization.  
- Demonstrate the potential of CNN-attention hybrid architectures in digital pathology.

---

## üß† Methodology

### 1. Data Preprocessing
- Dataset: **PatchCamelyon (PCam)** from **TensorFlow Datasets**
- Image resizing, normalization, and shuffling
- Data augmentation (rotation, flipping, contrast, zoom)
  
### 2. Model Architecture
| Layer | Type | Output Shape | Parameters |
|--------|------|---------------|-------------|
| Input | 96x96x3 | - |
| Conv2D | 32 filters, 3x3 kernel, ReLU | Feature Extraction |
| MaxPooling2D | 2x2 | Downsampling |
| Conv2D | 64 filters, 3x3 kernel, ReLU | Deep Features |
| Attention Layer | Context-based weighting | Focus on key regions |
| Flatten | - | - |
| Dense | 128 units, ReLU | Fully Connected |
| Dropout | 0.5 | Regularization |
| Dense | 1 unit, Sigmoid | Output Probability |

---

## üß© Mathematical Formulation

**CNN Convolution Operation:**

$$
O_{i,j} = \sum_{m} \sum_{n} I_{i+m, j+n} \cdot K_{m,n}
$$

**Attention Weighting:**

$$
\alpha_i = \frac{\exp(e_i)}{\sum_j \exp(e_j)} \quad \text{where} \quad e_i = v^T \tanh(W h_i)
$$

**Output:**

$$
y = \sigma(W_o \sum_i \alpha_i h_i + b)
$$

---

## üîç Flowchart

![Learning Curve](images/flow-chart.jpg)

---

## üìä Results

| Metric | Score |
|---------|--------|
| Accuracy | 0.94 |
| Precision | 0.93 |
| Recall | 0.92 |
| F1 Score | 0.93 |

**Visual Interpretability:**
- Confusion matrix shows model‚Äôs performance across classes.  
- Grad-CAM visualizations highlight cancerous regions focused on by the model.

---

## üñºÔ∏è Visualization

**Confusion Matrix (Enlarged)**  
![Confusion Matrix](images/confusion-matrix.png)

**Learning Curve (Next Line)**  
![Learning Curve](images/learning-curve.png)

---

## üí° Applications
- **Digital Pathology:** Automated screening for metastasis detection.  
- **Clinical Decision Support:** Assists oncologists by localizing cancerous regions.  
- **AI Explainability:** Transparent deep learning for healthcare diagnostics.

---

## ‚öôÔ∏è Tech Stack
**Python**, **TensorFlow**, **Keras**, **CNN + Attention Mechanism**, **Grad-CAM**,  
**TensorFlow Datasets**, **Scikit-learn**, **Matplotlib**, **Seaborn**

---

## üßæ Installation & Usage

```bash
# Clone the repository
git clone https://github.com/Aditya-Karan/PathoNet-X.git
cd PathoNet-X

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate   # For Linux/Mac
venv\Scripts\activate      # For Windows

# Install dependencies
pip install -r requirements.txt

# Train the model
python src/train.py

# Visualize results
python src/visualize.py
```

---

## üí° Applications
- **Early detection** of cancerous tissue from histopathological slides  
- **Assistive tool** for pathologists in diagnosis  
- **Model interpretability** for explainable AI in healthcare  

---

## üèÅ Conclusion
**PathoVision AI** demonstrates that combining **CNNs with attention mechanisms** enhances both **accuracy** and **explainability** in medical imaging tasks.  
The **Grad-CAM visualization** provides clear insight into model focus regions, making the system more **transparent**, **trustworthy**, and **clinically relevant**.

---

## üß∞ Future Improvements
- Integrate **transformer-based attention** (e.g., *Vision Transformer (ViT)* or *Swin Transformer*)  
- **Deploy** the trained model using **TensorFlow Serving** or **FastAPI** for real-world applications  
- Extend to **multi-class histopathological analysis** (e.g., multiple cancer subtypes)  


